{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19357d86-73e6-41a5-9009-9d02827ef9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490f1a11-8c9a-4a34-ab33-58225b1afdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Simulator.Exchange import Exchange\n",
    "from Simulator.Strategy import Strategy\n",
    "from Simulator.Order import Order\n",
    "from Simulator.OrderState import OrderState\n",
    "from TradeEnv.TradeGym import TradeEnv\n",
    "from Simulator.InverseInstrument import InverseInstrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c482f-1453-47b7-97ea-b9c269b7a685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  1 count:  86392 index:  44648\n",
      "{'balance': 0.01, 'trade_count': 63, 'trading_pnl_pct': 0.01, 'inventory_pnl_pct': -0.0, 'leverage': 0.02, 'reward': -0.0, 'steps': 1200}\n",
      "{'balance': 0.01, 'trade_count': 127, 'trading_pnl_pct': -0.02, 'inventory_pnl_pct': -0.05, 'leverage': 0.63, 'reward': -0.07, 'steps': 2400}\n",
      "{'balance': 0.01, 'trade_count': 161, 'trading_pnl_pct': -0.01, 'inventory_pnl_pct': 0.02, 'leverage': 0.54, 'reward': -0.01, 'steps': 3600}\n",
      "{'balance': 0.01, 'trade_count': 190, 'trading_pnl_pct': -0.0, 'inventory_pnl_pct': 0.04, 'leverage': 0.52, 'reward': -0.0, 'steps': 4800}\n",
      "{'balance': 0.01, 'trade_count': 235, 'trading_pnl_pct': -0.01, 'inventory_pnl_pct': -0.08, 'leverage': 0.87, 'reward': -0.09, 'steps': 6000}\n",
      "{'balance': 0.01, 'trade_count': 299, 'trading_pnl_pct': -0.06, 'inventory_pnl_pct': -0.17, 'leverage': 0.96, 'reward': -0.24, 'steps': 7200}\n",
      "{'balance': 0.01, 'trade_count': 365, 'trading_pnl_pct': -0.13, 'inventory_pnl_pct': 0.0, 'leverage': 0.59, 'reward': -0.13, 'steps': 8400}\n",
      "{'balance': 0.01, 'trade_count': 462, 'trading_pnl_pct': -0.18, 'inventory_pnl_pct': -0.02, 'leverage': 0.47, 'reward': -0.21, 'steps': 9600}\n",
      "{'balance': 0.01, 'trade_count': 501, 'trading_pnl_pct': -0.15, 'inventory_pnl_pct': 0.03, 'leverage': 0.16, 'reward': -0.15, 'steps': 10800}\n",
      "{'balance': 0.01, 'trade_count': 583, 'trading_pnl_pct': -0.11, 'inventory_pnl_pct': 0.1, 'leverage': 0.4, 'reward': -0.11, 'steps': 12000}\n",
      "{'balance': 0.01, 'trade_count': 765, 'trading_pnl_pct': -0.01, 'inventory_pnl_pct': -0.03, 'leverage': 0.63, 'reward': -0.04, 'steps': 13200}\n",
      "{'balance': 0.01, 'trade_count': 899, 'trading_pnl_pct': -0.03, 'inventory_pnl_pct': -0.14, 'leverage': 0.91, 'reward': -0.17, 'steps': 14400}\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import glob\n",
    "\n",
    "files = glob.glob(\"*.csv.gz\")\n",
    "\n",
    "model = None\n",
    "\n",
    "for file in files[:3]:\n",
    "    for j in range(0, 100):\n",
    "        df = pd.read_csv(file, header=0, index_col='timestamp', parse_dates=['timestamp'])\n",
    "        row_count = df.shape[0]\n",
    "        index = np.random.randint(low=0, high=row_count-7200)\n",
    "        print(\"iteration: \", j, \"count: \", row_count, \"index: \", index)\n",
    "        length = row_count - index + 1\n",
    "        instrument = InverseInstrument(\"BTC-PERPETUAL\", 0.5, 10, 0, 0.0005)\n",
    "        exchange = Exchange(df.iloc[index:, :])\n",
    "        strategy = Strategy(instrument, exchange, 0.01, 0.0002)\n",
    "        env = TradeEnv(strategy, \"human\")\n",
    "    \n",
    "        if model is None:\n",
    "            model = RecurrentPPO(\"MlpLstmPolicy\", env, verbose=0, gamma=.999, n_steps=120)\n",
    "        else:\n",
    "            model.set_env(env)\n",
    "        \n",
    "        model = model.learn(length, progress_bar=False)\n",
    "        clear_output(True)\n",
    "\n",
    "#vec_env = model.get_env()\n",
    "#mean_reward, std_reward = evaluate_policy(model, vec_env, n_eval_episodes=20, warn=False)\n",
    "#print(mean_reward)\n",
    "\n",
    "model.save(\"ppo_recurrent\")\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0fd9e9-8c69-4652-a59f-2c7cf74730ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentPPO.load(\"ppo_recurrent\")\n",
    "\n",
    "df = pd.read_csv(files[3], header=0, index_col='timestamp', parse_dates=['timestamp'])\n",
    "exchange = Exchange(df)\n",
    "strategy = Strategy(instrument, exchange, 0.02, 0.0002)\n",
    "env = TradeEnv(strategy, \"human\")\n",
    "obs, info = env.reset()\n",
    "\n",
    "# cell and hidden state of the LSTM\n",
    "lstm_states = None\n",
    "\n",
    "episode_start = 1\n",
    "done = False\n",
    "truncated = False\n",
    "while not done and not truncated:\n",
    "    action, lstm_states = model.predict(obs, state=lstm_states, episode_start=episode_start, deterministic=True)\n",
    "    obs, reward, done, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9697062f-49fa-4c52-b056-c1de6879daf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
